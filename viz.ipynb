{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: convert a nuscenes point cloud to a .las file for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import argparse\n",
    "import tqdm\n",
    "import pickle\n",
    "from functools import reduce\n",
    "from pyquaternion import Quaternion\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "from nuscenes.utils import splits\n",
    "from nuscenes.utils.geometry_utils import transform_matrix\n",
    "from typing import Optional, Union\n",
    "import laspy\n",
    "import numpy as np\n",
    "import pyproj\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from pointcept.datasets.preprocessing.nuscenes.preprocess_nuscenes_info import \\\n",
    "    get_available_scenes, get_sample_data, obtain_sensor2top, \\\n",
    "    quaternion_yaw, map_name_from_general_to_detection\n",
    "from pointcept.datasets.nuscenes import NuScenesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root='/mnt/d/nuscenes/nuScenes-lidarseg-all-v1.0'\n",
    "nusc_trainval = NuScenes(\n",
    "    version=\"v1.0-trainval\", dataroot=dataset_root, verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "850"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_scenes_trainval = get_available_scenes(nusc_trainval)\n",
    "available_scene_names_trainval = [s[\"name\"] for s in available_scenes_trainval]\n",
    "len(available_scenes_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'73030fb67d3c46cfb5e590168088ae39'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scenes = set(\n",
    "    [\n",
    "        available_scenes_trainval[available_scene_names_trainval.index(s)][\"token\"]\n",
    "        for s in splits.train[:1] # 1st one only\n",
    "    ]\n",
    ")\n",
    "train_scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scene=nusc_trainval.scene[0]\n",
    "# scene_token = scene[\"token\"]\n",
    "# scene_rec = nusc_trainval.get(\"scene\", scene_token)\n",
    "# sample_rec = nusc_trainval.get(\"sample\", scene_rec[\"first_sample_token\"])\n",
    "# sd_rec = nusc_trainval.get(\"sample_data\", sample_rec[\"data\"][\"LIDAR_TOP\"])\n",
    "# lidar_path, boxes, _ = nusc_trainval.get_sample_data(sd_rec[\"token\"])\n",
    "# Path(lidar_path).exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_trainval_infos(\n",
    "    data_path, nusc, train_scenes, test=False, max_sweeps=10, with_camera=False,\n",
    "    train_only=False\n",
    "):\n",
    "    train_nusc_infos = []\n",
    "    val_nusc_infos = []\n",
    "\n",
    "    ref_chan = \"LIDAR_TOP\"  # The radar channel from which we track back n sweeps to aggregate the point cloud.\n",
    "    chan = \"LIDAR_TOP\"  # The reference channel of the current sample_rec that the point clouds are mapped to.\n",
    "\n",
    "    samples=list(filter(lambda x: x[\"scene_token\"] in train_scenes, nusc.sample)) if train_only else nusc.sample\n",
    "    progress_bar = tqdm.tqdm(\n",
    "        total=len(samples), desc=\"create_info\", dynamic_ncols=True\n",
    "    )\n",
    "    for index, sample in enumerate(samples):\n",
    "        progress_bar.update()\n",
    "\n",
    "        ref_sd_token = sample[\"data\"][ref_chan]\n",
    "        ref_sd_rec = nusc.get(\"sample_data\", ref_sd_token)\n",
    "        ref_cs_rec = nusc.get(\n",
    "            \"calibrated_sensor\", ref_sd_rec[\"calibrated_sensor_token\"]\n",
    "        )\n",
    "        ref_pose_rec = nusc.get(\"ego_pose\", ref_sd_rec[\"ego_pose_token\"])\n",
    "        ref_time = 1e-6 * ref_sd_rec[\"timestamp\"]\n",
    "\n",
    "        ref_lidar_path, ref_boxes, _ = get_sample_data(nusc, ref_sd_token)\n",
    "\n",
    "        ref_cam_front_token = sample[\"data\"][\"CAM_FRONT\"]\n",
    "        ref_cam_path, _, ref_cam_intrinsic = nusc.get_sample_data(ref_cam_front_token)\n",
    "\n",
    "        # Homogeneous transform from ego car frame to reference frame\n",
    "        ref_from_car = transform_matrix(\n",
    "            ref_cs_rec[\"translation\"], Quaternion(ref_cs_rec[\"rotation\"]), inverse=True\n",
    "        )\n",
    "\n",
    "        # Homogeneous transformation matrix from global to _current_ ego car frame\n",
    "        car_from_global = transform_matrix(\n",
    "            ref_pose_rec[\"translation\"],\n",
    "            Quaternion(ref_pose_rec[\"rotation\"]),\n",
    "            inverse=True,\n",
    "        )\n",
    "        info = {\n",
    "            \"lidar_path\": Path(ref_lidar_path).relative_to(data_path).__str__(),\n",
    "            \"lidar_token\": ref_sd_token,\n",
    "            \"cam_front_path\": Path(ref_cam_path).relative_to(data_path).__str__(),\n",
    "            \"cam_intrinsic\": ref_cam_intrinsic,\n",
    "            \"token\": sample[\"token\"],\n",
    "            \"sweeps\": [],\n",
    "            \"ref_from_car\": ref_from_car,\n",
    "            \"car_from_global\": car_from_global,\n",
    "            \"timestamp\": ref_time,\n",
    "        }\n",
    "        if with_camera:\n",
    "            info[\"cams\"] = dict()\n",
    "            l2e_r = ref_cs_rec[\"rotation\"]\n",
    "            l2e_t = (ref_cs_rec[\"translation\"],)\n",
    "            e2g_r = ref_pose_rec[\"rotation\"]\n",
    "            e2g_t = ref_pose_rec[\"translation\"]\n",
    "            l2e_r_mat = Quaternion(l2e_r).rotation_matrix\n",
    "            e2g_r_mat = Quaternion(e2g_r).rotation_matrix\n",
    "\n",
    "            # obtain 6 image's information per frame\n",
    "            camera_types = [\n",
    "                \"CAM_FRONT\",\n",
    "                \"CAM_FRONT_RIGHT\",\n",
    "                \"CAM_FRONT_LEFT\",\n",
    "                \"CAM_BACK\",\n",
    "                \"CAM_BACK_LEFT\",\n",
    "                \"CAM_BACK_RIGHT\",\n",
    "            ]\n",
    "            for cam in camera_types:\n",
    "                cam_token = sample[\"data\"][cam]\n",
    "                cam_path, _, camera_intrinsics = nusc.get_sample_data(cam_token)\n",
    "                cam_info = obtain_sensor2top(\n",
    "                    nusc, cam_token, l2e_t, l2e_r_mat, e2g_t, e2g_r_mat, cam\n",
    "                )\n",
    "                cam_info[\"data_path\"] = (\n",
    "                    Path(cam_info[\"data_path\"]).relative_to(data_path).__str__()\n",
    "                )\n",
    "                cam_info.update(camera_intrinsics=camera_intrinsics)\n",
    "                info[\"cams\"].update({cam: cam_info})\n",
    "\n",
    "        sample_data_token = sample[\"data\"][chan]\n",
    "        curr_sd_rec = nusc.get(\"sample_data\", sample_data_token)\n",
    "        sweeps = []\n",
    "        while len(sweeps) < max_sweeps - 1:\n",
    "            if curr_sd_rec[\"prev\"] == \"\":\n",
    "                if len(sweeps) == 0:\n",
    "                    sweep = {\n",
    "                        \"lidar_path\": Path(ref_lidar_path)\n",
    "                        .relative_to(data_path)\n",
    "                        .__str__(),\n",
    "                        \"sample_data_token\": curr_sd_rec[\"token\"],\n",
    "                        \"transform_matrix\": None,\n",
    "                        \"time_lag\": curr_sd_rec[\"timestamp\"] * 0,\n",
    "                    }\n",
    "                    sweeps.append(sweep)\n",
    "                else:\n",
    "                    sweeps.append(sweeps[-1])\n",
    "            else:\n",
    "                curr_sd_rec = nusc.get(\"sample_data\", curr_sd_rec[\"prev\"])\n",
    "\n",
    "                # Get past pose\n",
    "                current_pose_rec = nusc.get(\"ego_pose\", curr_sd_rec[\"ego_pose_token\"])\n",
    "                global_from_car = transform_matrix(\n",
    "                    current_pose_rec[\"translation\"],\n",
    "                    Quaternion(current_pose_rec[\"rotation\"]),\n",
    "                    inverse=False,\n",
    "                )\n",
    "\n",
    "                # Homogeneous transformation matrix from sensor coordinate frame to ego car frame.\n",
    "                current_cs_rec = nusc.get(\n",
    "                    \"calibrated_sensor\", curr_sd_rec[\"calibrated_sensor_token\"]\n",
    "                )\n",
    "                car_from_current = transform_matrix(\n",
    "                    current_cs_rec[\"translation\"],\n",
    "                    Quaternion(current_cs_rec[\"rotation\"]),\n",
    "                    inverse=False,\n",
    "                )\n",
    "\n",
    "                tm = reduce(\n",
    "                    np.dot,\n",
    "                    [ref_from_car, car_from_global, global_from_car, car_from_current],\n",
    "                )\n",
    "\n",
    "                lidar_path = nusc.get_sample_data_path(curr_sd_rec[\"token\"])\n",
    "\n",
    "                time_lag = ref_time - 1e-6 * curr_sd_rec[\"timestamp\"]\n",
    "\n",
    "                sweep = {\n",
    "                    \"lidar_path\": Path(lidar_path).relative_to(data_path).__str__(),\n",
    "                    \"sample_data_token\": curr_sd_rec[\"token\"],\n",
    "                    \"transform_matrix\": tm,\n",
    "                    \"global_from_car\": global_from_car,\n",
    "                    \"car_from_current\": car_from_current,\n",
    "                    \"time_lag\": time_lag,\n",
    "                }\n",
    "                sweeps.append(sweep)\n",
    "\n",
    "        info[\"sweeps\"] = sweeps\n",
    "\n",
    "        assert len(info[\"sweeps\"]) == max_sweeps - 1, (\n",
    "            f\"sweep {curr_sd_rec['token']} only has {len(info['sweeps'])} sweeps, \"\n",
    "            f\"you should duplicate to sweep num {max_sweeps - 1}\"\n",
    "        )\n",
    "\n",
    "        if not test:\n",
    "            # processing gt bbox\n",
    "            annotations = [\n",
    "                nusc.get(\"sample_annotation\", token) for token in sample[\"anns\"]\n",
    "            ]\n",
    "\n",
    "            # the filtering gives 0.5~1 map improvement\n",
    "            num_lidar_pts = np.array([anno[\"num_lidar_pts\"] for anno in annotations])\n",
    "            num_radar_pts = np.array([anno[\"num_radar_pts\"] for anno in annotations])\n",
    "            mask = num_lidar_pts + num_radar_pts > 0\n",
    "\n",
    "            locs = np.array([b.center for b in ref_boxes]).reshape(-1, 3)\n",
    "            dims = np.array([b.wlh for b in ref_boxes]).reshape(-1, 3)[\n",
    "                :, [1, 0, 2]\n",
    "            ]  # wlh == > dxdydz (lwh)\n",
    "            velocity = np.array([b.velocity for b in ref_boxes]).reshape(-1, 3)\n",
    "            rots = np.array([quaternion_yaw(b.orientation) for b in ref_boxes]).reshape(\n",
    "                -1, 1\n",
    "            )\n",
    "            names = np.array([b.name for b in ref_boxes])\n",
    "            tokens = np.array([b.token for b in ref_boxes])\n",
    "            gt_boxes = np.concatenate([locs, dims, rots, velocity[:, :2]], axis=1)\n",
    "\n",
    "            assert len(annotations) == len(gt_boxes) == len(velocity)\n",
    "\n",
    "            info[\"gt_boxes\"] = gt_boxes[mask, :]\n",
    "            info[\"gt_boxes_velocity\"] = velocity[mask, :]\n",
    "            info[\"gt_names\"] = np.array(\n",
    "                [map_name_from_general_to_detection[name] for name in names]\n",
    "            )[mask]\n",
    "            info[\"gt_boxes_token\"] = tokens[mask]\n",
    "            info[\"num_lidar_pts\"] = num_lidar_pts[mask]\n",
    "            info[\"num_radar_pts\"] = num_radar_pts[mask]\n",
    "\n",
    "            # processing gt segment\n",
    "            segment_path = nusc.get(\"lidarseg\", ref_sd_token)[\"filename\"]\n",
    "            info[\"gt_segment_path\"] = segment_path\n",
    "\n",
    "        if sample[\"scene_token\"] in train_scenes:\n",
    "            train_nusc_infos.append(info)\n",
    "        else:\n",
    "            val_nusc_infos.append(info)\n",
    "\n",
    "    progress_bar.close()\n",
    "    return train_nusc_infos, val_nusc_infos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "create_info: 100%|██████████| 40/40 [00:00<00:00, 192.20it/s]\n"
     ]
    }
   ],
   "source": [
    "max_sweeps=10\n",
    "with_camera=False\n",
    "train_nusc_infos, _ = fill_trainval_infos(\n",
    "    dataset_root,\n",
    "    nusc_trainval,\n",
    "    train_scenes,\n",
    "    test=False,\n",
    "    max_sweeps=max_sweeps,\n",
    "    with_camera=with_camera,\n",
    "    train_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_root='../data'\n",
    "os.makedirs(os.path.join(output_root, \"info\"), exist_ok=True)\n",
    "with open(\n",
    "    os.path.join(\n",
    "        output_root,\n",
    "        \"info\",\n",
    "        f\"nuscenes_infos_{max_sweeps}sweeps_train.pkl\",\n",
    "    ),\n",
    "    \"wb\",\n",
    ") as f:\n",
    "    pickle.dump(train_nusc_infos, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-26 22:31:52,313 INFO defaults.py line 68 75257] Totally 40 x 1 samples in train set.\n"
     ]
    }
   ],
   "source": [
    "# type:ignore\n",
    "train_ds=NuScenesDataset(**dict(\n",
    "    # type='NuScenesDataset',\n",
    "    split=\"train\",\n",
    "    data_root=dataset_root,\n",
    "    transform=[\n",
    "        # dict(type=\"RandomDropout\", dropout_ratio=0.2, dropout_application_ratio=0.2),\n",
    "        # dict(type=\"RandomRotateTargetAngle\", angle=(1/2, 1, 3/2), center=[0, 0, 0], axis=\"z\", p=0.75),\n",
    "        dict(type=\"RandomRotate\", angle=[-1, 1], axis=\"z\", center=[0, 0, 0], p=0.5),\n",
    "        # dict(type=\"RandomRotate\", angle=[-1/6, 1/6], axis=\"x\", p=0.5),\n",
    "        # dict(type=\"RandomRotate\", angle=[-1/6, 1/6], axis=\"y\", p=0.5),\n",
    "        dict(type=\"RandomScale\", scale=[0.9, 1.1]),\n",
    "        # dict(type=\"RandomShift\", shift=[0.2, 0.2, 0.2]),\n",
    "        dict(type=\"RandomFlip\", p=0.5),\n",
    "        dict(type=\"RandomJitter\", sigma=0.005, clip=0.02),\n",
    "        # dict(type=\"ElasticDistortion\", distortion_params=[[0.2, 0.4], [0.8, 1.6]]),\n",
    "        dict(\n",
    "            type=\"GridSample\",\n",
    "            grid_size=0.05,\n",
    "            hash_type=\"fnv\",\n",
    "            mode=\"train\",\n",
    "            keys=(\"coord\", \"strength\", \"segment\"),\n",
    "            return_grid_coord=True,\n",
    "        ),\n",
    "        # dict(type=\"SphereCrop\", point_max=1000000, mode=\"random\"),\n",
    "        # dict(type=\"CenterShift\", apply_z=False),\n",
    "        dict(type=\"ToTensor\"),\n",
    "        dict(\n",
    "            type=\"Collect\",\n",
    "            keys=(\"coord\", \"grid_coord\", \"segment\"),\n",
    "            feat_keys=(\"coord\", \"strength\"),\n",
    "        ),\n",
    "    ],\n",
    "    test_mode=False,\n",
    "    ignore_index=-1,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'coord': tensor([[  5.5512, -36.6194,  -1.7120],\n",
       "         [  5.5730, -26.7211,   2.5473],\n",
       "         [  5.4475, -27.8848,   4.6742],\n",
       "         ...,\n",
       "         [  8.8255, -20.9018,   4.2864],\n",
       "         [  8.9210, -21.9589,  -1.6491],\n",
       "         [  8.8434, -22.6365,   1.6966]]),\n",
       " 'grid_coord': tensor([[2015, 1184,  199],\n",
       "         [2015, 1382,  284],\n",
       "         [2012, 1359,  327],\n",
       "         ...,\n",
       "         [2080, 1498,  319],\n",
       "         [2082, 1477,  201],\n",
       "         [2080, 1464,  267]]),\n",
       " 'segment': tensor([13, 15, 15,  ..., 15, 12, 15]),\n",
       " 'offset': tensor([22100]),\n",
       " 'feat': tensor([[  5.5512, -36.6194,  -1.7120,   0.0588],\n",
       "         [  5.5730, -26.7211,   2.5473,   0.0471],\n",
       "         [  5.4475, -27.8848,   4.6742,   0.0627],\n",
       "         ...,\n",
       "         [  8.8255, -20.9018,   4.2864,   0.0510],\n",
       "         [  8.9210, -21.9589,  -1.6491,   0.0392],\n",
       "         [  8.8434, -22.6365,   1.6966,   0.0627]])}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample=train_ds[0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PointCloud:\n",
    "    xyz: np.ndarray\n",
    "    rgb: Optional[np.ndarray]\n",
    "    crs: pyproj.CRS\n",
    "    classification: Optional[np.ndarray]\n",
    "\n",
    "class InvalidPointCloudError(Exception):\n",
    "    pass\n",
    "\n",
    "def check_point_cloud_validity(pcd:PointCloud):\n",
    "    n_xyz=len(pcd.xyz)\n",
    "    if not pcd.xyz.flags.contiguous:\n",
    "        raise InvalidPointCloudError('xyz not contiguous')\n",
    "    if pcd.rgb:\n",
    "        n_rgb=len(pcd.rgb)\n",
    "        if n_xyz!=n_rgb:\n",
    "            raise InvalidPointCloudError(f'Length of coords ({n_xyz}) and colors ({n_rgb}) do not match')\n",
    "        if not pcd.rgb.flags.contiguous:\n",
    "            raise InvalidPointCloudError('rgb not contiguous')\n",
    "\n",
    "def write_las_file(pcd: PointCloud, dst: Union[str,Path], replace:bool=False, mkparent:bool=True):\n",
    "    check_point_cloud_validity(pcd)\n",
    "    dst=Path(dst)\n",
    "    if dst.exists() and not replace:\n",
    "        raise FileExistsError(f'{dst} already exists, set `replace=True` to overwrite')\n",
    "    parentdir=dst.parent\n",
    "    if mkparent:\n",
    "        parentdir.mkdir(parents=True, exist_ok=True)\n",
    "    elif not parentdir.exists():\n",
    "        raise FileNotFoundError(f'Parent directory {parentdir} does not exist')\n",
    "\n",
    "    header = laspy.LasHeader(point_format=2, version='1.4')\n",
    "    if pcd.crs:\n",
    "        header.add_crs(pcd.crs)\n",
    "    las = laspy.LasData(header)\n",
    "    las.x = pcd.xyz[:,0]\n",
    "    las.y = pcd.xyz[:,1]\n",
    "    las.z = pcd.xyz[:,2]\n",
    "    if pcd.rgb is not None:\n",
    "        las.red = pcd.rgb[:,0]\n",
    "        las.green = pcd.rgb[:,1]\n",
    "        las.blue = pcd.rgb[:,2]\n",
    "    if pcd.classification is not None:\n",
    "        las.classification = pcd.classification\n",
    "    las.write(str(dst))\n",
    "    print('wrote', pcd.xyz.shape[0], 'points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote 22100 points\n"
     ]
    }
   ],
   "source": [
    "pcd=PointCloud(\n",
    "    xyz=sample['coord'].numpy(),\n",
    "    rgb=None,\n",
    "    crs=pyproj.CRS.from_epsg(3857),\n",
    "    classification=sample['segment'].numpy(),\n",
    ")\n",
    "write_las_file(pcd, '../data/sample.las', replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  626,   423,    20,     9,   232, 10444,     3,   848,  3794,\n",
       "        2767,  2934])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(sample['segment'].numpy(),return_counts=True)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: use a pretrained PointTransformerV3 model to predict the segmentation of a point cloud, and visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointcept2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
